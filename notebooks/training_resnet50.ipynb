{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921fb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import h5py\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b327dbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 05:06:59.964450: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 05:07:02.678940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-18 05:07:02.679358: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/pkgs/cudnn-8.1.0.77-h90431f1_0/lib/:/opt/conda/pkgs/cudatoolkit-11.2.2-he111cf0_8/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-18 05:07:02.679390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, Conv2D, Reshape, Add, ReLU, Dropout, \n",
    "    Flatten, Softmax, BatchNormalization, MaxPooling2D, AveragePooling2D\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e94a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set I/O path\n",
    "project_dir = Path.cwd().parent.resolve()\n",
    "\n",
    "data_dir = project_dir.joinpath('data')\n",
    "h5_dir = data_dir.joinpath('hdf5')\n",
    "h5_train_path = h5_dir.joinpath('train.h5')\n",
    "h5_test_path = h5_dir.joinpath('test.h5')\n",
    "\n",
    "log_dir = project_dir.joinpath('logs').joinpath('resnet50')\n",
    "model_dir = project_dir.joinpath('models').joinpath('resnet50')\n",
    "best_dir = model_dir.joinpath('best')\n",
    "latest_dir = model_dir.joinpath('latest')\n",
    "\n",
    "csv_log_path = project_dir.joinpath('csv_logs').joinpath('resnet50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4bfb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 05:07:05.380727: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 05:07:06.663573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10405 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:da:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "################################ Start of network construction #########################################\n",
    "################################# conv1  ################################## \n",
    "resnet50_conv1_input = Input(shape=( 256, 256, 3), name='conv1_input' )\n",
    "\n",
    "x = Conv2D(\n",
    "    64, kernel_size=7, strides=2, activation='relu',\n",
    "    padding='same', kernel_constraint=keras.constraints.max_norm(2.)\n",
    ")(resnet50_conv1_input)\n",
    "\n",
    "resnet50_conv1_output = MaxPooling2D(\n",
    "    pool_size=3, padding='same', strides=2\n",
    ")(x)\n",
    "\n",
    "\n",
    "\n",
    "resnet50_conv1 = Model( \n",
    "    inputs = resnet50_conv1_input,\n",
    "    outputs = resnet50_conv1_output, \n",
    "    name = \"ResNet-50_conv_1block\"\n",
    ")\n",
    "\n",
    "\n",
    "################################# conv2  ################################## \n",
    "# First Block of conv2 \n",
    "\n",
    "resnet50_conv2_first_block_input = Input(shape=(64,64,64), name='conv2_first_block_input' )\n",
    "x = Conv2D( 64, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv2_first_block_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 64, kernel_size=3, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 256, kernel_size=1, strides=1, padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "shortcut = Conv2D(\n",
    "    256, kernel_size=1, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.) \n",
    ")(resnet50_conv2_first_block_input)\n",
    "shortcut = BatchNormalization()(shortcut)\n",
    "x = Add()([x, shortcut])\n",
    "\n",
    "resnet50_conv2_first_block_output = ReLU()(x)\n",
    "\n",
    "resnet50_conv2_first_block = Model( \n",
    "    inputs = resnet50_conv2_first_block_input, \n",
    "    outputs = resnet50_conv2_first_block_output, \n",
    "    name = 'resnet50_conv2_first_block'\n",
    ")\n",
    "\n",
    "\n",
    "# Identity Block of conv2 \n",
    "resnet50_conv2_identity_block_input = Input(shape=(64,64,256), name='conv2_identity_block_input' )\n",
    "x = Conv2D( 64, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv2_identity_block_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 64, kernel_size=3, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 256, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Add()([x, resnet50_conv2_identity_block_input ])\n",
    "resnet50_conv2_identity_block_output = ReLU()(x)\n",
    "\n",
    "resnet50_conv2_identity_block = Model( \n",
    "    inputs = resnet50_conv2_identity_block_input, \n",
    "    outputs= resnet50_conv2_identity_block_output, \n",
    "    name = 'resnet50_conv2_identity_block'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Combining the 2 types of blocks \n",
    "resnet50_conv2_input = Input(shape=(64,64,64), name='resnet50_conv2_input')\n",
    "\n",
    "x = resnet50_conv2_first_block(resnet50_conv2_input)\n",
    "# x = resnet50_conv2_identity_block(resnet50_conv2_input)\n",
    "x = resnet50_conv2_identity_block(x)\n",
    "resnet50_conv2_output = resnet50_conv2_identity_block(x) \n",
    "\n",
    "resnet50_conv2 = Model(\n",
    "    inputs = resnet50_conv2_input, \n",
    "    outputs = resnet50_conv2_output, \n",
    "    name = \"ResNet-50_conv2_block\"\n",
    ")\n",
    "\n",
    "\n",
    "################################# conv3  ##################################\n",
    "# First Block of conv3 \n",
    "\n",
    "resnet50_conv3_first_block_input = Input(shape=(64,64,256), name='conv3_first_block_input' )\n",
    "x = Conv2D( 128, kernel_size=1, strides=2, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv3_first_block_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 128, kernel_size=3, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 512, kernel_size=1, strides=1, padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "shortcut = Conv2D(512, kernel_size=1, strides=2, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv3_first_block_input)\n",
    "shortcut = BatchNormalization()(shortcut)\n",
    "x = Add()([ x, shortcut])\n",
    "resnet50_conv3_first_block_output = ReLU()(x)\n",
    "\n",
    "resnet50_conv3_first_block = Model(\n",
    "    inputs  = resnet50_conv3_first_block_input, \n",
    "    outputs = resnet50_conv3_first_block_output, \n",
    "    name = 'resnet50_conv3_first_block'\n",
    ")\n",
    "\n",
    "\n",
    "# Identity Block of conv3 \n",
    "resnet50_conv3_identity_block_input = Input(shape=(32,32,512), name='conv3_identity_block_input' )\n",
    "x = Conv2D( 128, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv3_identity_block_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 128, kernel_size=3, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 512, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Add()([x, resnet50_conv3_identity_block_input ])\n",
    "resnet50_conv3_identity_block_output = ReLU()(x)\n",
    "\n",
    "resnet50_conv3_identity_block = Model( \n",
    "    inputs = resnet50_conv3_identity_block_input, \n",
    "    outputs= resnet50_conv3_identity_block_output, \n",
    "    name = 'resnet50_conv3_identity_block'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Combining the 2 types of blocks \n",
    "resnet50_conv3_input = Input(shape=(64,64,256), name='resnet50_conv3_input' )\n",
    "\n",
    "x = resnet50_conv3_first_block(resnet50_conv3_input)\n",
    "x = resnet50_conv3_identity_block(x)\n",
    "x = resnet50_conv3_identity_block(x)\n",
    "resnet50_conv3_output = resnet50_conv3_identity_block(x) \n",
    "\n",
    "resnet50_conv3 = Model(\n",
    "    inputs = resnet50_conv3_input, \n",
    "    outputs = resnet50_conv3_output, \n",
    "    name = \"ResNet-50_conv3_block\"\n",
    ")\n",
    "\n",
    "\n",
    " \n",
    "################################# conv4  ################################## \n",
    "# First Block of conv4\n",
    "\n",
    "resnet50_conv4_first_block_input = Input(shape=(32,32,512), name='conv4_first_block_input' )\n",
    "x = Conv2D( 256, kernel_size=1, strides=2, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv4_first_block_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 256, kernel_size=3, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 1024, kernel_size=1, strides=1, padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "shortcut = Conv2D(1024, kernel_size=1, strides=2, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv4_first_block_input)\n",
    "shortcut = BatchNormalization()(shortcut)\n",
    "x = Add()([ x, shortcut])\n",
    "resnet50_conv4_first_block_output = ReLU()(x)\n",
    "\n",
    "resnet50_conv4_first_block = Model(\n",
    "    inputs  = resnet50_conv4_first_block_input, \n",
    "    outputs = resnet50_conv4_first_block_output, \n",
    "    name = 'resnet50_conv4_first_block'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Identity Block of conv4\n",
    "resnet50_conv4_identity_block_input = Input(shape=(16,16,1024), name='conv4_identity_block_input' )\n",
    "x = Conv2D( 256, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv4_identity_block_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 256, kernel_size=3, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 1024, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Add()([x, resnet50_conv4_identity_block_input ])\n",
    "resnet50_conv4_identity_block_output = ReLU()(x)\n",
    "\n",
    "resnet50_conv4_identity_block = Model( \n",
    "    inputs = resnet50_conv4_identity_block_input, \n",
    "    outputs= resnet50_conv4_identity_block_output, \n",
    "    name = 'resnet50_conv4_identity_block'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combining the 2 types of blocks \n",
    "resnet50_conv4_input = Input(shape=(32,32,512), name='resnet50_conv4_input' )\n",
    "\n",
    "x = resnet50_conv4_first_block(resnet50_conv4_input)\n",
    "x = resnet50_conv4_identity_block(x)\n",
    "x = resnet50_conv4_identity_block(x)\n",
    "x = resnet50_conv4_identity_block(x)\n",
    "x = resnet50_conv4_identity_block(x)\n",
    "resnet50_conv4_output = resnet50_conv4_identity_block(x) \n",
    "\n",
    "resnet50_conv4 = Model(\n",
    "    inputs = resnet50_conv4_input, \n",
    "    outputs = resnet50_conv4_output, \n",
    "    name = \"ResNet-50_conv4_block\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "################################# conv5  ################################## \n",
    "# First Block of conv5\n",
    "resnet50_conv5_first_block_input = Input(shape=(16,16,1024), name='conv5_first_block_input' )\n",
    "x = Conv2D( 512, kernel_size=1, strides=2, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv5_first_block_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 512, kernel_size=3, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 2048, kernel_size=1, strides=1, padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "shortcut = Conv2D(2048, kernel_size=1, strides=2, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv5_first_block_input)\n",
    "shortcut = BatchNormalization()(shortcut)\n",
    "x = Add()([ x, shortcut])\n",
    "resnet50_conv5_first_block_output = ReLU()(x)\n",
    "\n",
    "resnet50_conv5_first_block = Model(\n",
    "    inputs  = resnet50_conv5_first_block_input, \n",
    "    outputs = resnet50_conv5_first_block_output, \n",
    "    name = 'resnet50_conv5_first_block'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Identity Block of conv5\n",
    "resnet50_conv5_identity_block_input = Input(shape=(8,8,2048), name='conv5_identity_block_input' )\n",
    "x = Conv2D( 512, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(resnet50_conv5_identity_block_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 512, kernel_size=3, strides=1, activation='relu', padding='same', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D( 2048, kernel_size=1, strides=1, activation='relu', padding='valid', kernel_constraint=keras.constraints.max_norm(2.))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Add()([x, resnet50_conv5_identity_block_input ])\n",
    "resnet50_conv5_identity_block_output = ReLU()(x)\n",
    "\n",
    "resnet50_conv5_identity_block = Model( \n",
    "    inputs = resnet50_conv5_identity_block_input, \n",
    "    outputs= resnet50_conv5_identity_block_output, \n",
    "    name = 'resnet50_conv5_identity_block'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combining the 2 types of blocks  \n",
    "resnet50_conv5_input = Input(shape=(16,16,1024), name='resnet50_conv5_input' )\n",
    "\n",
    "x = resnet50_conv5_first_block(resnet50_conv5_input)\n",
    "x = resnet50_conv5_identity_block(x)\n",
    "resnet50_conv5_output = resnet50_conv5_identity_block(x) \n",
    "\n",
    "resnet50_conv5 = Model(\n",
    "    inputs = resnet50_conv5_input, \n",
    "    outputs = resnet50_conv5_output, \n",
    "    name = \"ResNet-50_conv5_block\"\n",
    ")\n",
    "\n",
    "# tf.keras.utils.plot_model(resnet50_conv5, show_shapes=True, show_dtype=True)\n",
    "\n",
    "################################# classifier  ################################## \n",
    "# The classifier will tell us whether this event is \n",
    "# electron CC / muon CC / tauon CC / Neutral (4 types)\n",
    "\n",
    "\n",
    "resnet50_classifier_input = Input(shape=(8,8,2048), name='classification')\n",
    "x = AveragePooling2D(pool_size=2, padding='same')(resnet50_classifier_input)\n",
    "x = Dropout(0.2)(x) \n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "# I think it's 4, but if we want to classify more types of events \n",
    "# Need to change 4 to something else... \n",
    "number_of_categories = 5\n",
    "\n",
    "resnet50_classifier_output = Dense(\n",
    "    number_of_categories, activation='softmax', kernel_constraint=keras.constraints.max_norm(2.)\n",
    ")(x)\n",
    "\n",
    "\n",
    "resnet50_classifier = Model(\n",
    "    inputs = resnet50_classifier_input, \n",
    "    outputs= resnet50_classifier_output, \n",
    "    name = \"ResNet-50_Classifier\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################### \n",
    "def build_resnet50(optimizer, loss, metrics): \n",
    "    resnet50_input = Input(shape=( 256, 256, 3))\n",
    "    \n",
    "    # image Augumentation ?? \n",
    "    x = resnet50_input \n",
    "    \n",
    "    x = resnet50_conv1(x)  # do conv in this block  \n",
    "    x = resnet50_conv2(x)\n",
    "    x = resnet50_conv3(x)\n",
    "    x = resnet50_conv4(x)\n",
    "    x = resnet50_conv5(x)\n",
    "    \n",
    "    resnet50_output = resnet50_classifier(x)\n",
    "    \n",
    "    resnet50_model = Model( \n",
    "        inputs  = resnet50_input, \n",
    "        outputs = resnet50_output, \n",
    "        name = 'ResNet-50_Whole_Network'\n",
    "    )\n",
    "    \n",
    "    print( resnet50_model.summary() )\n",
    "        \n",
    "    resnet50_model.compile( \n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    return resnet50_model\n",
    "\n",
    "################################ End of network construction ######################################### \n",
    "    \n",
    "\n",
    "\n",
    "# tf.keras.utils.plot_model(resnet_obj, show_shapes=True, show_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e3e09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet-50_Whole_Network\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " ResNet-50_conv_1block (Func  (None, 64, 64, 64)       9472      \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " ResNet-50_conv2_block (Func  (None, 64, 64, 256)      148480    \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " ResNet-50_conv3_block (Func  (None, 32, 32, 512)      665600    \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " ResNet-50_conv4_block (Func  (None, 16, 16, 1024)     2641920   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " ResNet-50_conv5_block (Func  (None, 8, 8, 2048)       10526720  \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " ResNet-50_Classifier (Funct  (None, 5)                163845    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,156,037\n",
      "Trainable params: 14,125,317\n",
      "Non-trainable params: 30,720\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### define optimizerm, loss, metrics\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "\n",
    "\n",
    "ca = keras.metrics.CategoricalAccuracy(\n",
    "    name='categorical_accuracy', dtype=None\n",
    ")\n",
    "metrics = [ca]\n",
    "\n",
    "### build the resnet model and compile\n",
    "resnet50_network = build_resnet50(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414c320",
   "metadata": {},
   "source": [
    "### create a data generator for keras fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914147cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator:\n",
    "    def __init__(self, file, mode, batch_size):\n",
    "        self.file = file\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.length = self.compute_length()\n",
    "        \n",
    "        self.indices = None\n",
    "\n",
    "    def __call__(self):\n",
    "        self.indices = list(range(self.length))\n",
    "        random.shuffle(self.indices)\n",
    "            \n",
    "        with h5py.File(self.file, 'r') as hf:\n",
    "            for i in range(int(self.length/self.batch_size)-1): \n",
    "                sel_indices = [self.indices.pop() for _ in range(self.batch_size)]\n",
    "                sel_indices.sort()\n",
    "\n",
    "                sel_imgs = hf[f\"X_{self.mode}\"][sel_indices]\n",
    "                sel_labels = hf[f\"y_{self.mode}\"][sel_indices]\n",
    "\n",
    "                sel_imgs = sel_imgs.reshape(self.batch_size, 256, 256, 3)\n",
    "                sel_labels = sel_labels.reshape(self.batch_size, 5)\n",
    "\n",
    "                yield sel_imgs, sel_labels\n",
    "    \n",
    "    def compute_length(self):\n",
    "        length = 0\n",
    "        with h5py.File(self.file, 'r') as hf:\n",
    "            length = len(hf[f\"X_{self.mode}\"])\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05180083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(64, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(64, 5), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=64\n",
    "train_gen = generator(h5_train_path, mode='train', batch_size=batch_size)\n",
    "test_gen = generator(h5_test_path, mode='test', batch_size=batch_size)\n",
    "\n",
    "ds_train = tf.data.Dataset.from_generator(\n",
    "    train_gen,\n",
    "    output_signature=(\n",
    "         tf.TensorSpec(shape=(batch_size, 256, 256, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(batch_size, 5), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "ds_val = tf.data.Dataset.from_generator(\n",
    "    test_gen,\n",
    "    output_signature=(\n",
    "         tf.TensorSpec(shape=(batch_size, 256, 256, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(batch_size, 5), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "ds_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd1f68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 05:07:15.461831: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inResNet-50_Whole_Network/ResNet-50_Classifier/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-03-18 05:07:30.022370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-18 05:07:30.408346: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:31.613735: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fa46c04f350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-18 05:07:31.613780: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2023-03-18 05:07:31.620784: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-18 05:07:31.722078: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:31.799700: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-03-18 05:07:31.896866: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:32.453004: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:32.637136: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:33.012425: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:34.420107: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:35.032704: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:35.236047: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:35.645082: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:35.974007: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:38.245912: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:40.771400: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-18 05:07:42.920735: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.0.145, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    731/Unknown - 7805s 11s/step - loss: 1.9094 - categorical_accuracy: 0.4911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/best/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 16695s 23s/step - loss: 1.9094 - categorical_accuracy: 0.4911 - val_loss: 3.1181 - val_categorical_accuracy: 0.2208\n",
      "Epoch 2/500\n",
      "731/731 [==============================] - ETA: 0s - loss: 0.9210 - categorical_accuracy: 0.6127 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/best/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 13439s 18s/step - loss: 0.9210 - categorical_accuracy: 0.6127 - val_loss: 1.3331 - val_categorical_accuracy: 0.4167\n",
      "Epoch 3/500\n",
      "731/731 [==============================] - ETA: 0s - loss: 0.8605 - categorical_accuracy: 0.6419 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 13440s 18s/step - loss: 0.8605 - categorical_accuracy: 0.6419 - val_loss: 1.3863 - val_categorical_accuracy: 0.3754\n",
      "Epoch 4/500\n",
      "731/731 [==============================] - ETA: 0s - loss: 0.8414 - categorical_accuracy: 0.6556 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 13213s 18s/step - loss: 0.8414 - categorical_accuracy: 0.6556 - val_loss: 6.0145 - val_categorical_accuracy: 0.3145\n",
      "Epoch 5/500\n",
      "731/731 [==============================] - ETA: 0s - loss: 0.6758 - categorical_accuracy: 0.6736 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/best/assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 13484s 18s/step - loss: 0.6758 - categorical_accuracy: 0.6736 - val_loss: 0.8723 - val_categorical_accuracy: 0.5955\n",
      "Epoch 6/500\n",
      "731/731 [==============================] - ETA: 0s - loss: 0.8023 - categorical_accuracy: 0.6639 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 29). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hal113/teams/group-8/phys139-239_final_project/models/resnet50/latest/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 13552s 19s/step - loss: 0.8023 - categorical_accuracy: 0.6639 - val_loss: 1.5108 - val_categorical_accuracy: 0.4146\n",
      "Epoch 7/500\n",
      "595/731 [=======================>......] - ETA: 25:36 - loss: 0.6168 - categorical_accuracy: 0.6995"
     ]
    }
   ],
   "source": [
    "cb_tb = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "cb_csv = keras.callbacks.CSVLogger(csv_log_path)\n",
    "cb_save_best = keras.callbacks.ModelCheckpoint(filepath=best_dir, monitor='val_loss', save_best_only=True)\n",
    "cb_save_latest = keras.callbacks.ModelCheckpoint(filepath=latest_dir, monitor='val_loss', save_freq='epoch')\n",
    "\n",
    "callbacks = [cb_tb, cb_csv, cb_save_best, cb_save_latest]\n",
    "\n",
    "history = resnet50_network.fit(\n",
    "    x=ds_train, epochs=500,\n",
    "    validation_data=ds_val,\n",
    "    callbacks = callbacks,\n",
    "#     workers=8,\n",
    "#     use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37ba2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0259f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
